{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706528faaa238e0d",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:21.397937Z",
     "iopub.status.busy": "2025-11-17T02:27:21.397608Z",
     "iopub.status.idle": "2025-11-17T02:27:24.175901Z",
     "shell.execute_reply": "2025-11-17T02:27:24.175190Z",
     "shell.execute_reply.started": "2025-11-17T02:27:21.397910Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:21.615436Z",
     "start_time": "2025-11-26T23:31:20.510763Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# custom utility functions\n",
    "from modules.utils import Utils"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preliminary Setup",
   "id": "85f4c61d230612b5"
  },
  {
   "cell_type": "code",
   "id": "f4d90722a9bc307f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:24.182215Z",
     "iopub.status.busy": "2025-11-17T02:27:24.182014Z",
     "iopub.status.idle": "2025-11-17T02:27:24.191912Z",
     "shell.execute_reply": "2025-11-17T02:27:24.191397Z",
     "shell.execute_reply.started": "2025-11-17T02:27:24.182197Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:21.741881Z",
     "start_time": "2025-11-26T23:31:21.623800Z"
    }
   },
   "source": [
    "utils = Utils()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "d281e144ae71ef62",
   "metadata": {},
   "source": [
    "# Need the mean and std values from training set"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb70c15a468b35b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:28.346959Z",
     "iopub.status.busy": "2025-11-17T02:27:28.346077Z",
     "iopub.status.idle": "2025-11-17T02:27:33.724122Z",
     "shell.execute_reply": "2025-11-17T02:27:33.723347Z",
     "shell.execute_reply.started": "2025-11-17T02:27:28.346931Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:24.388362Z",
     "start_time": "2025-11-26T23:31:21.787936Z"
    }
   },
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "9518e3dd03dcd8b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:33.725617Z",
     "iopub.status.busy": "2025-11-17T02:27:33.725388Z",
     "iopub.status.idle": "2025-11-17T02:27:33.938002Z",
     "shell.execute_reply": "2025-11-17T02:27:33.937259Z",
     "shell.execute_reply.started": "2025-11-17T02:27:33.725595Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:24.485621Z",
     "start_time": "2025-11-26T23:31:24.395232Z"
    }
   },
   "source": [
    "# drop 'id' and 'label' for features\n",
    "X_df = df.drop(columns=['id', 'label'])\n",
    "\n",
    "# extract labels separately\n",
    "y_df = df['label']\n",
    "\n",
    "print(\"Number of feature columns:\", X_df.shape[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 500\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "724d7d8a4a0936cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:33.939185Z",
     "iopub.status.busy": "2025-11-17T02:27:33.938932Z",
     "iopub.status.idle": "2025-11-17T02:27:34.040137Z",
     "shell.execute_reply": "2025-11-17T02:27:34.039404Z",
     "shell.execute_reply.started": "2025-11-17T02:27:33.939168Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:24.545811Z",
     "start_time": "2025-11-26T23:31:24.491707Z"
    }
   },
   "source": [
    "X_tensor = torch.tensor(X_df.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_df, dtype=torch.long)\n",
    "\n",
    "print(X_tensor.shape)\n",
    "print(y_tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115406, 500])\n",
      "torch.Size([115406])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "473d6ca498cfc9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:27:34.045993Z",
     "iopub.status.busy": "2025-11-17T02:27:34.043794Z",
     "iopub.status.idle": "2025-11-17T02:27:34.416446Z",
     "shell.execute_reply": "2025-11-17T02:27:34.415832Z",
     "shell.execute_reply.started": "2025-11-17T02:27:34.045958Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:24.723894Z",
     "start_time": "2025-11-26T23:31:24.553544Z"
    }
   },
   "source": [
    "# NORMALIZING WITH MEAN 0 AND UNIT VARIANCE\n",
    "mean = X_tensor.mean(dim=0, keepdim=True)\n",
    "std = X_tensor.std(dim=0, unbiased=False, keepdim=True)\n",
    "\n",
    "# avoid division by zero for constant columns\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "X_tensor_norm = (X_tensor - mean) / std\n",
    "\n",
    "print(X_tensor_norm.shape)\n",
    "print(X_tensor_norm.mean(dim=0))  # should be ~0\n",
    "print(X_tensor_norm.std(dim=0))   # should be ~1\n",
    "\n",
    "# combine into a dataset\n",
    "dataset = TensorDataset(X_tensor_norm, y_tensor)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115406, 500])\n",
      "tensor([-6.8555e-08, -4.5615e-08,  1.3685e-08,  2.0196e-08, -1.8378e-08,\n",
      "        -7.7480e-08, -1.3883e-08, -2.7634e-08, -8.6405e-08, -8.4620e-09,\n",
      "        -2.9088e-08, -1.9965e-08, -2.1915e-08,  3.9732e-08, -3.6889e-08,\n",
      "         1.4544e-08,  3.8542e-08,  5.5532e-09,  3.7352e-08,  4.4128e-08,\n",
      "        -1.9998e-09, -4.4822e-08,  2.4857e-08,  2.0229e-08, -1.3883e-08,\n",
      "         4.0327e-09,  2.8030e-08,  3.0542e-08,  2.0890e-08, -8.6603e-09,\n",
      "         2.8890e-08, -1.3288e-08, -3.3848e-08,  4.3500e-08, -1.8048e-08,\n",
      "        -1.4263e-08,  1.2561e-09,  1.9833e-08, -2.1089e-08, -3.1468e-08,\n",
      "         2.1287e-08, -9.4701e-09,  1.9833e-09,  1.8709e-08, -3.8277e-08,\n",
      "         1.9568e-08, -3.9732e-08,  1.9172e-09, -5.5267e-08,  1.5271e-08,\n",
      "        -7.8670e-09,  2.0031e-08, -6.3465e-09, -2.1485e-09, -8.1645e-09,\n",
      "         2.6642e-08,  4.7202e-08,  6.0027e-08, -3.1865e-08, -1.6924e-08,\n",
      "         3.4972e-08, -4.0988e-08, -4.4954e-09, -6.6407e-08,  8.7661e-08,\n",
      "        -4.4095e-08, -2.3865e-08,  1.1239e-08,  3.5963e-08,  2.1419e-08,\n",
      "         4.2310e-08, -5.2094e-08, -8.4686e-08, -2.6576e-08, -3.6096e-08,\n",
      "         6.5613e-09,  5.3020e-08, -1.5536e-08,  6.9580e-09, -1.6858e-09,\n",
      "        -6.4523e-08, -1.2164e-08, -1.8511e-08,  1.8114e-08, -7.6885e-08,\n",
      "         2.5254e-08,  2.0725e-08, -1.4808e-08, -1.3222e-09,  3.4773e-08,\n",
      "         6.5283e-09, -6.2804e-09,  1.7387e-08, -4.8921e-09,  2.8361e-08,\n",
      "        -1.4015e-08, -8.2636e-10, -3.5765e-08, -6.1151e-09, -2.5783e-08,\n",
      "        -1.5866e-09, -3.4906e-08,  1.9172e-08,  1.3486e-08, -1.9502e-08,\n",
      "        -2.0560e-08,  2.2609e-08,  2.1155e-09, -2.9815e-08,  5.4077e-08,\n",
      "        -5.8837e-09,  6.6109e-09,  5.9829e-09, -4.6871e-08,  3.3914e-08,\n",
      "        -3.0278e-08,  1.8841e-08,  2.7237e-08, -2.6973e-08, -9.7842e-09,\n",
      "        -3.0609e-08,  3.2724e-08,  2.4394e-08,  1.8742e-08, -3.3055e-08,\n",
      "         2.1353e-08,  2.9617e-08,  6.0192e-08,  3.1732e-09, -5.0177e-08,\n",
      "        -7.7678e-09,  2.8129e-08,  4.5946e-08, -2.2576e-08,  4.6276e-09,\n",
      "         2.1419e-08, -2.2411e-08, -1.8511e-09,  1.7254e-08, -2.2312e-08,\n",
      "         5.3416e-08, -1.4808e-08, -3.9203e-08,  2.3799e-08, -2.9749e-08,\n",
      "        -1.2296e-08, -7.5364e-09, -2.3733e-08, -2.7568e-08, -5.3548e-08,\n",
      "         2.2675e-08, -3.9004e-08, -2.6774e-08, -3.8079e-08,  1.0710e-08,\n",
      "         9.3214e-09,  3.0385e-08, -3.1534e-08, -3.1204e-08, -7.6026e-09,\n",
      "        -3.0278e-08, -2.5121e-09, -1.2032e-08,  4.2178e-08, -4.2359e-08,\n",
      "         3.4112e-08, -5.5466e-08, -6.6109e-11, -1.7552e-08,  3.3253e-08,\n",
      "         4.1649e-08, -1.8246e-08,  4.5748e-08,  6.3200e-08, -1.4114e-08,\n",
      "        -8.6603e-09, -1.0049e-08,  2.3006e-08, -7.0208e-08, -2.8559e-08,\n",
      "        -2.4460e-08, -1.3172e-08, -5.6193e-09,  6.7233e-08,  1.9568e-08,\n",
      "         8.1314e-09, -2.4064e-08, -3.6426e-08,  2.8824e-08, -1.3371e-08,\n",
      "        -1.1404e-08,  4.0525e-08,  4.1764e-08, -3.4840e-08,  2.8030e-08,\n",
      "        -4.6276e-09,  2.6080e-08,  6.5118e-09, -2.1155e-08,  4.1153e-08,\n",
      "         2.8559e-08,  5.2226e-08, -3.2393e-09,  1.6197e-09,  2.5518e-08,\n",
      "        -8.5281e-09,  1.2891e-08, -2.7964e-08,  3.9666e-10,  2.1535e-08,\n",
      "        -6.1878e-08,  4.8921e-09,  2.2808e-08,  4.1781e-08, -2.5419e-08,\n",
      "        -2.9088e-08, -6.5613e-09,  6.9018e-08,  3.0939e-08,  4.1120e-08,\n",
      "         1.7849e-08, -6.5779e-09, -5.7118e-08, -4.2310e-08, -5.6854e-09,\n",
      "        -2.5915e-08, -9.3875e-09, -1.3916e-08,  2.6179e-08,  1.9072e-08,\n",
      "        -3.5699e-08, -3.6294e-08,  4.7599e-09, -1.1900e-08, -2.6642e-08,\n",
      "         4.1715e-08,  1.3420e-08,  3.7814e-08, -2.4593e-08,  1.7998e-08,\n",
      "         1.3222e-10,  3.7748e-08, -1.2296e-08, -4.3235e-08, -3.4707e-09,\n",
      "         1.1106e-08, -2.8691e-08,  2.9815e-08, -7.9331e-09,  5.3813e-08,\n",
      "         4.2442e-08,  2.0097e-08,  1.3883e-08, -3.9533e-08, -2.3799e-08,\n",
      "         1.0710e-08, -3.9930e-08, -1.3552e-08,  2.9286e-08, -3.5897e-08,\n",
      "        -4.4161e-08, -5.1301e-08, -1.6131e-08,  2.9419e-08, -4.8689e-08,\n",
      "         6.5448e-08, -4.7499e-08,  2.4328e-08, -6.1482e-09, -5.4672e-08,\n",
      "        -2.6146e-08, -2.9617e-08,  4.6805e-08,  4.1186e-08, -9.3049e-09,\n",
      "         1.3486e-08,  1.2693e-08,  5.4210e-09, -1.2032e-08,  7.3513e-08,\n",
      "        -1.3354e-08, -2.0890e-08, -2.6906e-08, -1.5734e-08,  2.9088e-09,\n",
      "         2.3337e-08,  2.5849e-08,  5.0309e-08,  1.0181e-08,  1.2131e-08,\n",
      "         3.2096e-08,  1.1437e-08, -1.6180e-08,  9.2553e-10, -4.3103e-08,\n",
      "         6.3465e-09, -6.6109e-11, -1.4875e-10, -3.8343e-09, -6.0820e-09,\n",
      "        -9.2553e-10,  2.7105e-09,  2.6576e-08,  3.8013e-09,  7.9397e-08,\n",
      "        -1.4147e-08,  3.4245e-08,  3.7748e-08, -7.8670e-09,  2.3932e-08,\n",
      "         3.3583e-08, -2.2907e-08, -4.2310e-09,  2.1419e-08,  3.2790e-08,\n",
      "         5.9498e-09,  3.0741e-09, -7.5364e-09,  1.3090e-08,  2.4857e-08,\n",
      "        -1.4412e-08, -1.5866e-09, -8.2636e-09,  3.7947e-08, -4.2310e-08,\n",
      "        -3.8145e-08,  8.2636e-09,  6.5779e-09,  2.9815e-08,  3.6691e-08,\n",
      "         3.2922e-08,  5.3945e-08, -4.4128e-09, -1.5337e-08, -2.0097e-08,\n",
      "        -3.7484e-08,  3.4112e-08, -2.3865e-08, -3.3716e-08,  4.2442e-08,\n",
      "        -7.9331e-10,  7.0076e-09,  2.4659e-08, -2.1750e-08, -3.0080e-08,\n",
      "         7.3613e-08, -2.2477e-09,  3.7616e-08,  1.1767e-08, -4.0062e-08,\n",
      "         1.1503e-08, -1.9965e-08,  2.0163e-08, -2.7369e-08, -5.6193e-09,\n",
      "        -1.3817e-08, -3.4377e-09, -1.3106e-08, -7.2390e-09, -8.8586e-09,\n",
      "         1.8643e-08,  1.7056e-08, -2.5121e-09, -1.9172e-09, -2.9088e-08,\n",
      "        -1.4676e-08, -1.5866e-09, -2.5849e-08,  2.6245e-08, -1.9833e-10,\n",
      "         8.0918e-08, -1.8577e-08, -2.7948e-08, -3.5038e-09, -3.3583e-08,\n",
      "         1.5403e-08, -2.2659e-08, -6.7431e-09, -1.3585e-08,  1.3420e-08,\n",
      "         2.7634e-08,  1.6478e-08, -2.0494e-08, -1.9436e-08, -8.5942e-09,\n",
      "         3.2129e-08, -2.1221e-08, -4.9251e-08,  4.9846e-08, -1.1635e-08,\n",
      "         4.7070e-08, -1.1048e-08,  6.6770e-09,  2.8956e-08,  2.3006e-08,\n",
      "        -4.7516e-08,  3.0179e-08,  2.3799e-08,  3.8839e-08,  2.3601e-08,\n",
      "        -1.5602e-08,  2.0494e-09, -1.4544e-08,  2.6840e-08, -3.6757e-08,\n",
      "         1.9833e-09,  2.1816e-09,  1.3883e-08,  1.8577e-08, -1.3883e-09,\n",
      "         4.3566e-08,  5.9300e-08, -3.6261e-08, -2.3403e-08,  3.8575e-08,\n",
      "        -1.2296e-08,  8.7925e-09,  1.4875e-08,  7.1398e-09, -1.9833e-09,\n",
      "         3.7352e-09, -3.7682e-08,  1.3057e-09,  2.3998e-08,  5.5399e-08,\n",
      "        -3.0675e-08, -7.6356e-09, -2.4460e-09,  3.0939e-08, -1.0049e-08,\n",
      "        -3.2261e-08, -7.1398e-09,  4.5615e-09, -5.1830e-08, -6.6109e-09,\n",
      "         5.0904e-09,  2.2477e-09, -2.0626e-08,  1.8709e-08,  1.5602e-08,\n",
      "         9.7180e-09, -6.4787e-09, -1.7849e-09, -3.3385e-08, -1.5602e-08,\n",
      "        -2.7039e-08,  1.9172e-08, -3.0741e-08, -2.2477e-09,  1.9039e-08,\n",
      "        -5.5119e-08,  7.1728e-09, -2.6973e-08,  1.2296e-08,  1.0049e-08,\n",
      "         3.7054e-08, -3.4245e-08,  8.5942e-10,  2.1010e-08,  5.3879e-09,\n",
      "        -2.4196e-08,  6.1812e-08, -4.5615e-09, -1.8180e-08,  4.0789e-08,\n",
      "        -2.2180e-08,  2.9088e-09,  2.1552e-08,  6.9580e-09, -1.0577e-08,\n",
      "        -4.5714e-08,  5.0970e-08,  1.5139e-08,  2.9881e-08,  1.0049e-08,\n",
      "        -7.9331e-10,  5.4375e-08, -1.2462e-08, -4.2310e-09,  3.8740e-08,\n",
      "        -4.2971e-09, -6.4787e-09, -4.0194e-08,  5.1565e-09, -4.4954e-08,\n",
      "        -1.6065e-08, -2.0229e-08,  1.4676e-08,  2.4989e-08,  6.1614e-08,\n",
      "        -4.0657e-09,  6.0820e-09, -9.3214e-09,  3.5831e-08, -4.4558e-08,\n",
      "         8.7264e-09, -2.2708e-08,  4.3632e-09,  2.5518e-08,  1.7056e-08])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "90849ae9e2c7412",
   "metadata": {},
   "source": "# Retrain the model from Random Search on the FULL TRAIN SET"
  },
  {
   "cell_type": "code",
   "id": "2d92cc81ecaaf2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T02:36:29.523672Z",
     "iopub.status.busy": "2025-11-17T02:36:29.523376Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:41:58.358576Z",
     "start_time": "2025-11-26T23:31:24.729988Z"
    }
   },
   "source": [
    "# Medium MLP first submission w/modified architecture, gets 0.827 on FULL TRAIN SET\n",
    "# grad_clip=True, gauss=True, patience=10. HITS 81.05% VAL ACC\n",
    "params = {'hidden_size': 4096, 'lr': 0.001, 'weight_decay': 0.1, 'batch_size': 512, 'init_type': 'xavier', 'dropout': 0.5, 'noise_std': 0.65, 'num_epochs': 100, 'warmup_epochs': 12}\n",
    "\n",
    "# reduce batch size from 768 to 512 and noise 0.65? >>> 81.11% [will submit this one on Kaggle, gets 81.05% val acc on laptop]\n",
    "#                                                              [RESUBMITTING WITH TRAINING ON THE FULL TRAIN SET INSTEAD OF THE TRAIN SUBSET]\n",
    "\n",
    "# Medium MLP second submission w/modified architecture, gets 0.834 on FULL TRAIN SET\n",
    "# grad_clip=True, gauss=True, patience=10. HITS 81.45% VAL ACC\n",
    "params = {'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.05, 'batch_size': 512, 'init_type': 'xavier', 'dropout': 0.5, 'noise_std': 0.6, 'num_epochs': 100, 'warmup_epochs': 12}\n",
    "\n",
    "# Medium MLP third submission w/modified architecture, gets 0.839 on FULL TRAIN SET\n",
    "# grad_clip=True, gauss=True, patience=10. HITS 81.93% VAL ACC\n",
    "# grad_clip=True, gauss=True, patience=10, label_smoothing=0.15, max_norm=10.0. HITS 82.65% VAL ACC\n",
    "params = {'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.05, 'batch_size': 512, 'init_type': 'xavier', 'dropout': 0.5, 'noise_std': 0.6, 'num_epochs': 125, 'warmup_epochs': 12}\n",
    "\n",
    "model = utils.train(\n",
    "    dataset, device, params=params, grad_clip=True, gauss=True\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bef2f72f0e124090a7649511d529b00d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the model",
   "id": "6113b1707fcf7ded"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:01.689108Z",
     "start_time": "2025-11-26T23:42:01.600788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "utils.save_checkpoint(model, params, f'./models/FULL-MediumMLP-model-ckpt-{timestamp}.pth', full_train_dataset=True)"
   ],
   "id": "3cad45cbb4f3945",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Option 2: Load the model trained on FULL TRAIN SET",
   "id": "92a58a5e11ae0439"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T23:31:10.997335148Z",
     "start_time": "2025-11-26T23:28:14.539299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path should be ./models/FULL-<the rest>\n",
    "path = './models/FULL-MediumMLP-model-ckpt-2025-11-26_18-42-01.pth'\n",
    "model, params = utils.load_checkpoint(path, device, full_train_dataset=True)"
   ],
   "id": "7123e293588f4d38",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "b0af8d40f9d62234",
   "metadata": {},
   "source": [
    "# Initialize test set"
   ]
  },
  {
   "cell_type": "code",
   "id": "523526b87b5ae916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:19:46.754916Z",
     "iopub.status.busy": "2025-11-16T20:19:46.754534Z",
     "iopub.status.idle": "2025-11-16T20:19:49.238469Z",
     "shell.execute_reply": "2025-11-16T20:19:49.237944Z",
     "shell.execute_reply.started": "2025-11-16T20:19:46.754891Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:38.087791Z",
     "start_time": "2025-11-26T23:42:36.269721Z"
    }
   },
   "source": [
    "df_test_clean = pd.read_csv('./data/test.csv')\n",
    "\n",
    "df_test = df_test_clean.drop(columns=['id'])\n",
    "df_test.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.000000        0.0   0.113592        0.0        0.0   0.000000   \n",
       "1   0.113228        0.0   0.000000        0.0        0.0   0.113228   \n",
       "2   0.000000        0.0   0.000000        0.0        0.0   0.000000   \n",
       "3   0.000000        0.0   0.000000        0.0        0.0   0.000000   \n",
       "4   0.000000        0.0   0.000000        0.0        0.0   0.000000   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_490  feature_491  \\\n",
       "0   0.000000        0.0        0.0   0.000000  ...          0.0     0.000000   \n",
       "1   0.226455        0.0        0.0   0.113228  ...          0.0     0.113228   \n",
       "2   0.000000        0.0        0.0   0.104828  ...          0.0     0.000000   \n",
       "3   0.000000        0.0        0.0   0.000000  ...          0.0     0.000000   \n",
       "4   0.000000        0.0        0.0   0.000000  ...          0.0     0.000000   \n",
       "\n",
       "   feature_492  feature_493  feature_494  feature_495  feature_496  \\\n",
       "0     0.170389     0.000000     0.056796     0.000000     0.056796   \n",
       "1     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2     0.000000     0.000000     0.209657     0.104828     0.000000   \n",
       "3     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4     0.000000     0.109764     0.000000     0.000000     0.000000   \n",
       "\n",
       "   feature_497  feature_498  feature_499  \n",
       "0     0.000000          0.0          0.0  \n",
       "1     0.000000          0.0          0.0  \n",
       "2     0.000000          0.0          0.0  \n",
       "3     0.000000          0.0          0.0  \n",
       "4     0.109764          0.0          0.0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_490</th>\n",
       "      <th>feature_491</th>\n",
       "      <th>feature_492</th>\n",
       "      <th>feature_493</th>\n",
       "      <th>feature_494</th>\n",
       "      <th>feature_495</th>\n",
       "      <th>feature_496</th>\n",
       "      <th>feature_497</th>\n",
       "      <th>feature_498</th>\n",
       "      <th>feature_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>0.226455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209657</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7476bbaf0816cb31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:19:49.242401Z",
     "iopub.status.busy": "2025-11-16T20:19:49.241870Z",
     "iopub.status.idle": "2025-11-16T20:19:49.368624Z",
     "shell.execute_reply": "2025-11-16T20:19:49.367757Z",
     "shell.execute_reply.started": "2025-11-16T20:19:49.242377Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:38.842890Z",
     "start_time": "2025-11-26T23:42:38.724Z"
    }
   },
   "source": [
    "# NORMALIZE WITH THE SAME MEAN/STD OBTAINED FROM THE TRAINING SET\n",
    "test_tensor = torch.tensor(df_test.values, dtype=torch.float32)\n",
    "\n",
    "# Apply same training mean/std\n",
    "test_tensor_norm = (test_tensor - mean) / std\n",
    "\n",
    "print(test_tensor_norm.shape)\n",
    "print(test_tensor_norm.mean(dim=0))  # should be ~0\n",
    "print(test_tensor_norm.std(dim=0))   # should be ~1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49460, 500])\n",
      "tensor([-5.3581e-04,  3.1035e-03,  1.0709e-02, -4.0309e-03,  6.5904e-03,\n",
      "         1.3172e-03,  4.1022e-03, -1.2916e-03, -1.0826e-02, -2.2387e-04,\n",
      "        -1.8983e-03, -2.9043e-03, -6.9165e-04, -7.7687e-03, -1.9963e-03,\n",
      "        -3.7147e-03, -8.7191e-03,  3.6268e-03, -3.0633e-03, -1.7393e-03,\n",
      "        -3.6079e-03, -3.8107e-03,  6.9915e-03,  7.1280e-03,  3.6513e-03,\n",
      "         6.3325e-03, -4.6298e-03,  2.9175e-03, -3.7233e-03,  5.6264e-03,\n",
      "         5.4351e-03,  4.6136e-03, -9.8161e-04,  3.4426e-03,  3.9129e-03,\n",
      "        -6.3146e-03, -4.1739e-03, -6.3719e-03,  1.1527e-04, -7.9489e-03,\n",
      "        -4.6441e-03,  6.3852e-03, -5.6621e-03,  2.5581e-03, -3.6894e-03,\n",
      "        -6.6946e-03,  1.0695e-02,  4.9246e-03,  7.8550e-03,  1.5818e-03,\n",
      "         4.2177e-03, -3.1513e-03, -5.2909e-03, -2.0714e-03,  6.0393e-04,\n",
      "        -4.7644e-03,  4.5614e-03, -3.3923e-03, -7.5719e-03,  1.6721e-03,\n",
      "         5.4259e-03, -1.4520e-02, -5.7779e-03, -8.1507e-03, -7.2291e-04,\n",
      "        -2.5344e-03,  2.9130e-03, -5.1013e-03,  3.8944e-03,  3.3341e-03,\n",
      "         5.2827e-03, -6.6061e-03, -1.0883e-03,  4.2465e-03,  1.8424e-03,\n",
      "         8.0364e-03,  3.9071e-03,  3.7545e-03,  1.1705e-05,  1.1344e-02,\n",
      "        -3.4392e-03,  2.4743e-03, -9.9697e-03,  7.2015e-03, -6.5378e-03,\n",
      "        -1.3414e-02, -6.9414e-03,  1.6179e-03, -7.4215e-03,  1.3103e-04,\n",
      "        -3.6489e-03, -4.5781e-03, -1.2642e-03,  1.6456e-03,  5.2239e-03,\n",
      "         1.1146e-02, -6.5849e-03, -1.7927e-03, -3.0934e-03, -3.9333e-03,\n",
      "        -1.0330e-03,  1.8187e-04,  1.1007e-03, -1.7024e-03,  6.5891e-03,\n",
      "         3.8178e-03,  5.3874e-03,  5.1091e-04, -2.7034e-03,  3.0555e-04,\n",
      "         1.6770e-03, -1.8305e-03,  9.5116e-03, -5.4138e-04, -4.4740e-03,\n",
      "        -6.6185e-03, -1.0466e-02, -7.8555e-03,  1.8717e-03,  8.2327e-04,\n",
      "        -2.5098e-03, -7.2422e-03, -6.1320e-03, -6.8238e-04, -3.7310e-03,\n",
      "         1.0690e-03,  2.8568e-03, -9.2158e-04, -1.3222e-03,  7.1423e-03,\n",
      "        -1.1087e-03, -3.5195e-03,  6.9574e-03,  6.5162e-03, -5.1714e-03,\n",
      "         1.4213e-03, -2.5134e-03, -1.2173e-03, -8.4745e-04,  1.0290e-03,\n",
      "        -2.6052e-03, -7.5929e-03, -2.7499e-03,  1.8281e-03, -6.8275e-03,\n",
      "         3.2226e-03,  6.2149e-04,  8.6827e-04,  3.9995e-03,  1.3494e-03,\n",
      "         2.4512e-03, -3.7474e-04,  4.1216e-03, -6.7165e-03,  3.1853e-03,\n",
      "        -6.1644e-03, -3.5109e-03,  6.0793e-03,  1.1325e-02, -9.9981e-04,\n",
      "        -6.1538e-03, -5.1808e-03,  3.2893e-03, -5.0934e-03,  2.1720e-03,\n",
      "        -6.2875e-04,  7.2191e-03,  2.8001e-03,  2.7737e-03, -6.8638e-03,\n",
      "         6.7891e-03,  1.9474e-03,  2.9467e-04,  5.3814e-03,  2.0411e-03,\n",
      "         3.0593e-04, -6.4512e-03, -6.2814e-03,  8.1813e-04,  4.2284e-03,\n",
      "        -4.8479e-03, -4.7006e-03,  7.0236e-03, -8.6134e-03, -3.2901e-03,\n",
      "         3.2762e-03, -2.3034e-03, -1.0425e-03, -6.5844e-03, -1.2859e-02,\n",
      "        -1.0537e-03,  2.6101e-03,  1.9354e-03, -9.7040e-03,  4.4672e-04,\n",
      "        -9.6309e-03, -7.6096e-04, -1.8255e-03,  5.6288e-03, -1.0583e-03,\n",
      "         4.9425e-04,  5.0753e-04, -9.5333e-03, -9.9569e-04,  6.9863e-03,\n",
      "        -2.5349e-03, -1.8332e-04,  8.0142e-04,  1.2509e-03,  1.4140e-03,\n",
      "         1.3422e-02,  1.2312e-02,  3.5427e-03, -6.9824e-04, -5.5540e-03,\n",
      "         2.9306e-04,  3.4380e-03,  5.3385e-03, -3.9498e-03, -1.0850e-02,\n",
      "        -4.2034e-03,  2.6877e-04, -3.5026e-03,  1.8525e-04,  5.7432e-03,\n",
      "         7.6769e-03, -2.0871e-03,  8.9130e-04,  3.3086e-03, -6.4284e-03,\n",
      "        -5.6735e-04, -5.0564e-03, -4.4684e-03, -1.6558e-03, -8.5531e-03,\n",
      "        -6.2649e-03,  5.2457e-04, -9.4728e-04, -1.1759e-02, -4.0487e-03,\n",
      "         3.6078e-03,  2.2405e-03,  2.0489e-03, -1.6964e-03, -1.0489e-03,\n",
      "        -1.5464e-03,  4.1689e-04, -3.2662e-03, -6.6746e-03,  4.5800e-03,\n",
      "        -8.4185e-04, -1.2365e-03,  6.6753e-04, -2.3609e-03, -5.9527e-03,\n",
      "        -8.3064e-03,  2.9384e-03, -8.4584e-03,  3.7689e-03,  8.7062e-03,\n",
      "        -3.7200e-03,  1.3394e-03,  6.8892e-03, -2.8527e-03,  2.2706e-03,\n",
      "         4.2203e-03,  4.4535e-04,  1.4534e-03,  1.3321e-03, -2.8401e-04,\n",
      "        -1.6832e-04, -5.3442e-03,  4.0376e-03,  3.5403e-03,  2.9111e-03,\n",
      "        -5.1661e-03, -1.4259e-02, -3.1891e-03, -7.6906e-03, -4.2120e-04,\n",
      "        -3.1920e-03, -1.1550e-02,  1.6694e-03,  7.5425e-04, -5.7164e-03,\n",
      "         5.6398e-03,  8.1479e-03,  6.9607e-04,  1.5484e-03,  7.0229e-03,\n",
      "        -1.6597e-04,  1.0160e-03,  6.5098e-03,  3.1101e-03, -9.8020e-03,\n",
      "        -3.7825e-03,  4.8447e-03, -9.4164e-03, -1.3493e-03,  2.4819e-03,\n",
      "        -3.1839e-03, -7.6445e-03, -1.3039e-03,  6.0275e-03, -2.7300e-03,\n",
      "         8.3561e-04,  1.4410e-03, -5.9678e-05, -5.0519e-04, -3.9156e-03,\n",
      "         1.1517e-02, -2.5595e-05, -7.8136e-03, -1.5642e-04, -2.1037e-04,\n",
      "        -7.6402e-03, -5.1881e-03, -1.5762e-03,  8.1498e-04,  3.1468e-03,\n",
      "        -2.1550e-03, -1.6116e-03, -2.7467e-03,  1.5898e-03, -4.6425e-04,\n",
      "         2.0451e-03, -1.1999e-02, -8.5678e-03, -1.7649e-03, -3.8149e-03,\n",
      "        -3.5777e-03,  3.4737e-04,  5.6165e-04,  4.2146e-03,  2.0334e-03,\n",
      "        -1.2544e-02, -2.4389e-03, -1.4154e-02, -1.5955e-02,  3.6695e-04,\n",
      "         2.9210e-03,  1.6408e-03, -7.8730e-03,  3.0105e-03, -9.6093e-03,\n",
      "        -4.6066e-03, -1.2563e-02, -4.8229e-03,  1.5294e-04, -1.2744e-04,\n",
      "        -5.4799e-03,  4.8668e-03, -1.6846e-03, -5.3670e-03, -3.7375e-03,\n",
      "        -3.7342e-03, -5.7594e-03, -1.8597e-03, -2.4007e-03,  4.1934e-03,\n",
      "        -1.5382e-04, -5.1802e-03, -1.4058e-03, -1.3807e-03, -7.0053e-03,\n",
      "         6.6298e-03,  8.1093e-03, -3.1319e-04,  9.1638e-03,  1.7133e-03,\n",
      "         4.5218e-04, -3.6471e-03,  2.0541e-03,  5.6276e-03, -4.2024e-03,\n",
      "         9.0161e-03, -3.4314e-03, -7.5814e-03,  7.4519e-03,  4.7319e-03,\n",
      "         1.6959e-03, -7.3068e-03,  2.1716e-03,  8.5101e-03,  1.2647e-03,\n",
      "         1.7641e-03, -1.0132e-03, -1.5080e-02,  1.0067e-02,  1.3029e-03,\n",
      "         1.7262e-04, -1.4784e-03,  4.9203e-03, -7.7575e-03,  5.1139e-03,\n",
      "         2.3582e-05,  5.8775e-03, -8.3182e-03,  6.6607e-03, -3.1747e-03,\n",
      "         2.5582e-03, -6.1972e-03, -2.2985e-03, -4.0396e-03, -1.7058e-03,\n",
      "         5.5267e-03, -3.6120e-03,  1.2913e-02, -1.0262e-02,  6.8114e-03,\n",
      "         7.7763e-03,  2.8059e-03, -1.3285e-03,  5.2094e-03, -8.0115e-03,\n",
      "        -2.1290e-03, -4.3787e-03, -8.3892e-03, -1.7211e-03, -4.8818e-03,\n",
      "        -3.8770e-04, -6.3019e-03, -4.6660e-03,  1.6545e-04,  7.1240e-03,\n",
      "         3.5043e-03,  3.3480e-03,  3.9161e-03,  3.5984e-03,  5.0560e-03,\n",
      "        -3.9787e-03,  9.8715e-03,  3.8659e-03, -2.9511e-03,  6.3263e-03,\n",
      "        -4.7226e-03, -8.3846e-04,  5.6283e-04, -3.6443e-04,  5.4492e-03,\n",
      "        -4.4397e-03, -2.5588e-03,  5.0398e-03, -3.5376e-03,  2.2175e-03,\n",
      "         3.8351e-03, -5.4568e-03,  8.9008e-04, -1.0347e-02,  2.8187e-03,\n",
      "        -3.2763e-03,  2.8740e-04, -9.4524e-03,  4.7121e-03, -1.1585e-03,\n",
      "        -1.0422e-04, -3.5482e-03,  2.2810e-03,  2.4752e-03,  2.4911e-03,\n",
      "        -5.2570e-03,  3.7438e-03, -7.3711e-03,  1.3382e-03, -4.5685e-03,\n",
      "        -3.0563e-03, -4.2148e-03, -2.2128e-03,  4.1975e-03, -1.3649e-02,\n",
      "        -7.0274e-03,  4.0884e-04,  3.8179e-03,  6.4355e-03, -7.5672e-03,\n",
      "        -1.1791e-03, -1.9904e-03,  5.1583e-03, -6.8872e-03,  2.0109e-03,\n",
      "        -5.0632e-03, -5.1797e-03, -1.2383e-03, -7.6264e-03, -2.7747e-03,\n",
      "         5.4794e-03,  2.4571e-04, -1.8312e-03, -3.2347e-03, -4.4798e-03,\n",
      "         4.0960e-04,  2.8816e-03,  4.6058e-03,  1.0217e-03, -4.0385e-03,\n",
      "        -3.4130e-03, -5.2093e-03,  4.1431e-03, -3.5926e-03, -3.5351e-03])\n",
      "tensor([1.0082, 1.0120, 1.0122, 1.0032, 1.0086, 1.0030, 1.0025, 1.0210, 0.9850,\n",
      "        0.9988, 0.9948, 1.0007, 1.0110, 0.9898, 1.0046, 0.9970, 0.9931, 1.0052,\n",
      "        0.9897, 0.9999, 0.9773, 0.9928, 1.0050, 1.0045, 1.0169, 1.0191, 0.9902,\n",
      "        1.0023, 0.9857, 1.0133, 1.0051, 1.0058, 0.9926, 1.0075, 1.0057, 0.9955,\n",
      "        0.9951, 0.9852, 0.9942, 0.9943, 0.9864, 1.0111, 0.9906, 1.0142, 0.9916,\n",
      "        0.9718, 1.0205, 1.0131, 1.0099, 0.9923, 1.0074, 0.9979, 0.9971, 0.9927,\n",
      "        0.9977, 0.9948, 1.0014, 0.9980, 0.9952, 0.9958, 1.0111, 0.9774, 0.9916,\n",
      "        0.9927, 0.9951, 0.9917, 1.0038, 0.9905, 1.0099, 1.0076, 1.0018, 0.9871,\n",
      "        0.9981, 1.0160, 1.0125, 1.0141, 1.0121, 1.0084, 1.0050, 1.0165, 0.9954,\n",
      "        1.0063, 0.9753, 1.0092, 0.9851, 0.9790, 0.9835, 1.0034, 0.9917, 1.0038,\n",
      "        0.9951, 0.9895, 1.0072, 1.0044, 1.0101, 1.0128, 0.9910, 0.9984, 0.9951,\n",
      "        1.0000, 1.0027, 0.9949, 1.0040, 0.9952, 1.0203, 1.0170, 1.0030, 1.0056,\n",
      "        0.9908, 1.0041, 1.0037, 0.9898, 1.0156, 1.0036, 0.9917, 0.9821, 0.9890,\n",
      "        0.9912, 1.0012, 0.9945, 1.0028, 0.9878, 0.9917, 1.0096, 0.9873, 1.0056,\n",
      "        1.0104, 0.9992, 0.9936, 1.0159, 0.9878, 0.9913, 1.0072, 0.9970, 0.9909,\n",
      "        1.0088, 1.0028, 0.9950, 0.9958, 0.9917, 0.9990, 0.9854, 0.9917, 1.0053,\n",
      "        0.9923, 0.9983, 1.0094, 1.0066, 1.0056, 1.0040, 0.9951, 0.9996, 1.0071,\n",
      "        0.9767, 0.9970, 0.9921, 0.9986, 1.0166, 1.0167, 0.9956, 0.9991, 0.9935,\n",
      "        1.0139, 0.9861, 1.0066, 0.9964, 1.0171, 1.0101, 1.0035, 0.9980, 1.0118,\n",
      "        1.0051, 1.0044, 1.0037, 1.0012, 1.0022, 0.9924, 0.9887, 1.0014, 1.0046,\n",
      "        0.9999, 0.9964, 1.0162, 0.9908, 0.9986, 0.9916, 1.0035, 0.9865, 0.9977,\n",
      "        0.9704, 1.0042, 1.0060, 1.0034, 0.9790, 0.9933, 0.9885, 1.0027, 1.0037,\n",
      "        1.0011, 0.9918, 1.0069, 1.0076, 0.9840, 1.0056, 1.0197, 0.9870, 0.9917,\n",
      "        0.9994, 1.0012, 0.9966, 1.0228, 1.0145, 1.0097, 1.0015, 0.9969, 1.0021,\n",
      "        1.0062, 1.0137, 0.9888, 0.9847, 0.9886, 0.9912, 1.0011, 1.0043, 1.0107,\n",
      "        1.0125, 0.9987, 1.0043, 1.0099, 0.9865, 1.0011, 1.0018, 1.0064, 0.9986,\n",
      "        0.9835, 0.9842, 1.0000, 1.0041, 0.9833, 0.9933, 1.0050, 1.0075, 1.0027,\n",
      "        1.0014, 1.0048, 0.9959, 1.0021, 0.9959, 0.9884, 1.0025, 0.9916, 0.9979,\n",
      "        0.9962, 0.9982, 0.9913, 0.9893, 1.0036, 0.9818, 0.9991, 1.0180, 0.9993,\n",
      "        0.9995, 1.0191, 0.9899, 1.0115, 1.0134, 0.9978, 1.0069, 1.0020, 0.9882,\n",
      "        0.9960, 0.9895, 1.0058, 1.0118, 1.0152, 0.9959, 0.9744, 1.0074, 0.9963,\n",
      "        1.0002, 0.9919, 0.9859, 1.0010, 1.0017, 0.9906, 1.0076, 1.0156, 0.9982,\n",
      "        0.9900, 1.0192, 1.0113, 0.9855, 1.0097, 0.9928, 0.9908, 0.9981, 1.0134,\n",
      "        0.9788, 0.9997, 1.0082, 0.9971, 0.9878, 0.9907, 1.0073, 0.9894, 1.0090,\n",
      "        1.0062, 1.0056, 0.9938, 0.9941, 1.0271, 0.9968, 0.9796, 1.0056, 1.0050,\n",
      "        0.9885, 0.9923, 0.9952, 1.0098, 1.0101, 0.9887, 0.9974, 0.9927, 0.9887,\n",
      "        0.9981, 1.0053, 0.9790, 0.9844, 0.9951, 0.9868, 0.9889, 0.9895, 1.0044,\n",
      "        1.0038, 1.0007, 0.9795, 1.0010, 0.9867, 0.9792, 1.0065, 1.0056, 0.9961,\n",
      "        0.9943, 0.9922, 0.9908, 1.0029, 0.9765, 0.9959, 1.0025, 0.9975, 0.9953,\n",
      "        1.0127, 0.9928, 0.9944, 1.0002, 0.9871, 0.9893, 0.9935, 0.9923, 1.0085,\n",
      "        1.0062, 0.9995, 0.9973, 1.0033, 0.9960, 1.0191, 1.0026, 1.0048, 1.0223,\n",
      "        1.0125, 1.0004, 0.9975, 1.0097, 1.0153, 0.9943, 1.0242, 0.9913, 0.9891,\n",
      "        1.0219, 1.0048, 1.0101, 0.9851, 0.9976, 1.0167, 1.0059, 1.0047, 0.9958,\n",
      "        0.9831, 1.0146, 1.0177, 0.9980, 1.0008, 1.0122, 0.9950, 1.0110, 1.0080,\n",
      "        1.0062, 0.9860, 1.0056, 0.9985, 1.0064, 0.9911, 1.0033, 1.0079, 0.9998,\n",
      "        1.0391, 0.9898, 1.0129, 0.9873, 1.0129, 1.0162, 1.0200, 1.0060, 1.0079,\n",
      "        0.9870, 1.0059, 0.9918, 0.9922, 1.0099, 0.9948, 0.9962, 0.9944, 0.9936,\n",
      "        1.0044, 1.0155, 1.0011, 1.0027, 1.0057, 1.0037, 1.0073, 0.9939, 1.0048,\n",
      "        1.0355, 0.9986, 1.0188, 0.9981, 1.0008, 0.9957, 1.0058, 1.0061, 0.9894,\n",
      "        0.9943, 1.0021, 1.0019, 1.0051, 1.0095, 0.9909, 1.0033, 0.9889, 1.0002,\n",
      "        0.9910, 1.0035, 0.9861, 1.0060, 0.9963, 1.0046, 0.9938, 1.0086, 0.9994,\n",
      "        1.0051, 0.9870, 1.0082, 0.9855, 1.0027, 1.0002, 0.9959, 0.9926, 1.0025,\n",
      "        1.0068, 0.9809, 0.9892, 0.9988, 1.0076, 1.0161, 0.9906, 0.9939, 0.9903,\n",
      "        1.0112, 0.9878, 1.0044, 0.9971, 0.9926, 0.9948, 0.9896, 0.9921, 1.0103,\n",
      "        1.0005, 1.0018, 0.9979, 1.0001, 0.9960, 1.0156, 1.0057, 1.0026, 0.9972,\n",
      "        0.9936, 0.9924, 1.0033, 0.9924, 0.9906])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "44e1b461a67a8307",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "406a483b1ca95aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:19:49.371465Z",
     "iopub.status.busy": "2025-11-16T20:19:49.371271Z",
     "iopub.status.idle": "2025-11-16T20:19:50.034955Z",
     "shell.execute_reply": "2025-11-16T20:19:50.034055Z",
     "shell.execute_reply.started": "2025-11-16T20:19:49.371446Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:48.024623Z",
     "start_time": "2025-11-26T23:42:47.238524Z"
    }
   },
   "source": [
    "test_set = TensorDataset(test_tensor_norm) # PUT THE NORMALIZED TEST TENSOR, NOT THE RAW ONE\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_batch,) in test_loader: # make sure to unpack tuple from TensorDataset\n",
    "        X_batch = X_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1) # class 0-49\n",
    "        predictions.extend(preds.cpu().numpy()) # move to cpu >>> convert to numpy\n",
    "\n",
    "preds_df = pd.DataFrame({\n",
    "    'id': df_test_clean['id'].values,   # original test IDs\n",
    "    'label': predictions                # predicted class labels\n",
    "})\n",
    "preds_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id  label\n",
       "0          0      0\n",
       "1          1      7\n",
       "2          2      3\n",
       "3          3     15\n",
       "4          4     42\n",
       "...      ...    ...\n",
       "49455  49455     35\n",
       "49456  49456     43\n",
       "49457  49457      3\n",
       "49458  49458     47\n",
       "49459  49459      7\n",
       "\n",
       "[49460 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49455</th>\n",
       "      <td>49455</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>49456</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>49457</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>49458</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49459</th>\n",
       "      <td>49459</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49460 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "189bd6c7e8db2c44",
   "metadata": {},
   "source": [
    "# Save predictions and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "4520812ae41075b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:19:50.038783Z",
     "iopub.status.busy": "2025-11-16T20:19:50.038585Z",
     "iopub.status.idle": "2025-11-16T20:19:50.073981Z",
     "shell.execute_reply": "2025-11-16T20:19:50.073327Z",
     "shell.execute_reply.started": "2025-11-16T20:19:50.038759Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:49.063143Z",
     "start_time": "2025-11-26T23:42:49.036655Z"
    }
   },
   "source": [
    "# CSV\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"./submissions/MediumMLP-predictions-{timestamp}.csv\"\n",
    "preds_df.to_csv(filename, index=False)\n",
    "\n",
    "# JSON\n",
    "filename = f'./submissions/MediumMLP-params-{timestamp}.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(params, f, indent=4)\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    loaded_params = json.load(f)\n",
    "\n",
    "print(loaded_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.05, 'batch_size': 512, 'init_type': 'xavier', 'dropout': 0.5, 'noise_std': 0.6, 'num_epochs': 125, 'warmup_epochs': 12}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "15fbd464c25d44c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T20:19:50.076981Z",
     "iopub.status.busy": "2025-11-16T20:19:50.076784Z",
     "iopub.status.idle": "2025-11-16T20:19:50.084285Z",
     "shell.execute_reply": "2025-11-16T20:19:50.083502Z",
     "shell.execute_reply.started": "2025-11-16T20:19:50.076963Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-26T23:42:50.418426Z",
     "start_time": "2025-11-26T23:42:50.409666Z"
    }
   },
   "source": [
    "class_counts = preds_df['label'].value_counts().sort_index()\n",
    "print(class_counts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     1011\n",
      "1      915\n",
      "2      982\n",
      "3      988\n",
      "4      981\n",
      "5      981\n",
      "6      937\n",
      "7     1025\n",
      "8     1013\n",
      "9      848\n",
      "10     922\n",
      "11     932\n",
      "12    1048\n",
      "13     957\n",
      "14    1021\n",
      "15     921\n",
      "16     963\n",
      "17    1063\n",
      "18    1006\n",
      "19     965\n",
      "20    1036\n",
      "21     925\n",
      "22    1062\n",
      "23    1103\n",
      "24    1006\n",
      "25    1088\n",
      "26     934\n",
      "27    1037\n",
      "28     949\n",
      "29     991\n",
      "30     906\n",
      "31     951\n",
      "32    1052\n",
      "33     961\n",
      "34    1009\n",
      "35    1009\n",
      "36     982\n",
      "37     945\n",
      "38     989\n",
      "39    1025\n",
      "40    1113\n",
      "41     919\n",
      "42    1019\n",
      "43     945\n",
      "44    1055\n",
      "45     955\n",
      "46    1032\n",
      "47    1029\n",
      "48     997\n",
      "49     957\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d07ab6350b2300e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
