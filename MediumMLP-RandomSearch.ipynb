{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e64e975b756ea5a",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:33.233524Z",
     "iopub.status.busy": "2025-11-16T22:57:33.232841Z",
     "iopub.status.idle": "2025-11-16T22:57:36.189235Z",
     "shell.execute_reply": "2025-11-16T22:57:36.188278Z",
     "shell.execute_reply.started": "2025-11-16T22:57:33.233489Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:30.702008Z",
     "start_time": "2025-11-28T03:07:29.527805Z"
    }
   },
   "source": [
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "from modules.utils import Utils"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3a17f957d7eb0404",
   "metadata": {},
   "source": [
    "# Preliminary Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "5cdb8c2232c1bf2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:37.549352Z",
     "iopub.status.busy": "2025-11-16T22:57:37.548765Z",
     "iopub.status.idle": "2025-11-16T22:57:37.573626Z",
     "shell.execute_reply": "2025-11-16T22:57:37.572861Z",
     "shell.execute_reply.started": "2025-11-16T22:57:37.549321Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:30.827349Z",
     "start_time": "2025-11-28T03:07:30.712094Z"
    }
   },
   "source": [
    "utils = Utils()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "dd72605e5f10dac4",
   "metadata": {},
   "source": "# Exploring the Data"
  },
  {
   "cell_type": "code",
   "id": "aca644b80f241f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:39.381534Z",
     "iopub.status.busy": "2025-11-16T22:57:39.380542Z",
     "iopub.status.idle": "2025-11-16T22:57:45.189055Z",
     "shell.execute_reply": "2025-11-16T22:57:45.188143Z",
     "shell.execute_reply.started": "2025-11-16T22:57:39.381499Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.461397Z",
     "start_time": "2025-11-28T03:07:30.874643Z"
    }
   },
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d3077bc65daf07c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.190898Z",
     "iopub.status.busy": "2025-11-16T22:57:45.190648Z",
     "iopub.status.idle": "2025-11-16T22:57:45.211705Z",
     "shell.execute_reply": "2025-11-16T22:57:45.210759Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.190875Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.488965Z",
     "start_time": "2025-11-28T03:07:33.469019Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1   1   0.000000   0.000000   0.000000   0.071982   0.000000   0.000000   \n",
       "2   2   0.111111   0.000000   0.111111   0.000000   0.000000   0.111111   \n",
       "3   3   0.000000   0.087039   0.000000   0.000000   0.000000   0.000000   \n",
       "4   4   0.000000   0.000000   0.069673   0.000000   0.069673   0.000000   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_491  feature_492  \\\n",
       "0   0.000000   0.000000   0.000000  ...     0.000000     0.000000   \n",
       "1   0.000000   0.071982   0.000000  ...     0.000000     0.000000   \n",
       "2   0.000000   0.111111   0.000000  ...     0.000000     0.111111   \n",
       "3   0.000000   0.000000   0.087039  ...     0.000000     0.000000   \n",
       "4   0.069673   0.000000   0.000000  ...     0.069673     0.000000   \n",
       "\n",
       "   feature_493  feature_494  feature_495  feature_496  feature_497  \\\n",
       "0          0.0          0.0          0.0          0.0     0.000000   \n",
       "1          0.0          0.0          0.0          0.0     0.071982   \n",
       "2          0.0          0.0          0.0          0.0     0.000000   \n",
       "3          0.0          0.0          0.0          0.0     0.000000   \n",
       "4          0.0          0.0          0.0          0.0     0.000000   \n",
       "\n",
       "   feature_498  feature_499  label  \n",
       "0          0.0     0.063888     43  \n",
       "1          0.0     0.000000     16  \n",
       "2          0.0     0.000000     21  \n",
       "3          0.0     0.000000      2  \n",
       "4          0.0     0.000000      1  \n",
       "\n",
       "[5 rows x 502 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_491</th>\n",
       "      <th>feature_492</th>\n",
       "      <th>feature_493</th>\n",
       "      <th>feature_494</th>\n",
       "      <th>feature_495</th>\n",
       "      <th>feature_496</th>\n",
       "      <th>feature_497</th>\n",
       "      <th>feature_498</th>\n",
       "      <th>feature_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 502 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3b56e0b914b1153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.213120Z",
     "iopub.status.busy": "2025-11-16T22:57:45.212910Z",
     "iopub.status.idle": "2025-11-16T22:57:45.218545Z",
     "shell.execute_reply": "2025-11-16T22:57:45.217496Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.213100Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.527594Z",
     "start_time": "2025-11-28T03:07:33.524479Z"
    }
   },
   "source": [
    "df['label'].head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43\n",
       "1    16\n",
       "2    21\n",
       "3     2\n",
       "4     1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3d10f63ae0c14bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.220454Z",
     "iopub.status.busy": "2025-11-16T22:57:45.220243Z",
     "iopub.status.idle": "2025-11-16T22:57:45.303701Z",
     "shell.execute_reply": "2025-11-16T22:57:45.302884Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.220434Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.619641Z",
     "start_time": "2025-11-28T03:07:33.573315Z"
    }
   },
   "source": [
    "# verify for any rows with null values\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts[null_counts > 0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "93ffc77207f8f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.304925Z",
     "iopub.status.busy": "2025-11-16T22:57:45.304724Z",
     "iopub.status.idle": "2025-11-16T22:57:45.525615Z",
     "shell.execute_reply": "2025-11-16T22:57:45.524760Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.304905Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.709693Z",
     "start_time": "2025-11-28T03:07:33.625815Z"
    }
   },
   "source": [
    "# drop 'id' and 'label' for features\n",
    "X_df = df.drop(columns=['id', 'label'])\n",
    "\n",
    "# extract labels separately\n",
    "y_df = df['label']\n",
    "\n",
    "print(\"Number of feature columns:\", X_df.shape[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 500\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "79d76a6d4b390229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.527194Z",
     "iopub.status.busy": "2025-11-16T22:57:45.526961Z",
     "iopub.status.idle": "2025-11-16T22:57:45.533413Z",
     "shell.execute_reply": "2025-11-16T22:57:45.532698Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.527173Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.726835Z",
     "start_time": "2025-11-28T03:07:33.718845Z"
    }
   },
   "source": [
    "# verifying class count distribution\n",
    "class_counts = y_df.value_counts().sort_index()\n",
    "print(class_counts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     2309\n",
      "1     2306\n",
      "2     2307\n",
      "3     2309\n",
      "4     2309\n",
      "5     2309\n",
      "6     2310\n",
      "7     2307\n",
      "8     2304\n",
      "9     2309\n",
      "10    2307\n",
      "11    2307\n",
      "12    2310\n",
      "13    2308\n",
      "14    2307\n",
      "15    2303\n",
      "16    2305\n",
      "17    2309\n",
      "18    2309\n",
      "19    2309\n",
      "20    2310\n",
      "21    2307\n",
      "22    2310\n",
      "23    2309\n",
      "24    2309\n",
      "25    2304\n",
      "26    2308\n",
      "27    2310\n",
      "28    2309\n",
      "29    2310\n",
      "30    2310\n",
      "31    2308\n",
      "32    2310\n",
      "33    2310\n",
      "34    2309\n",
      "35    2309\n",
      "36    2307\n",
      "37    2305\n",
      "38    2309\n",
      "39    2307\n",
      "40    2310\n",
      "41    2310\n",
      "42    2308\n",
      "43    2308\n",
      "44    2306\n",
      "45    2310\n",
      "46    2307\n",
      "47    2305\n",
      "48    2310\n",
      "49    2309\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "b301c55606a2170",
   "metadata": {},
   "source": [
    "# Processing Data for Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "id": "95b1eedefae12c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.534996Z",
     "iopub.status.busy": "2025-11-16T22:57:45.534296Z",
     "iopub.status.idle": "2025-11-16T22:57:45.600420Z",
     "shell.execute_reply": "2025-11-16T22:57:45.599537Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.534974Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.823539Z",
     "start_time": "2025-11-28T03:07:33.770341Z"
    }
   },
   "source": [
    "X_tensor = torch.tensor(X_df.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_df, dtype=torch.long)\n",
    "\n",
    "print(X_tensor.shape)\n",
    "print(y_tensor.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115406, 500])\n",
      "torch.Size([115406])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2af12982d76bb6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.602049Z",
     "iopub.status.busy": "2025-11-16T22:57:45.601317Z",
     "iopub.status.idle": "2025-11-16T22:57:45.846607Z",
     "shell.execute_reply": "2025-11-16T22:57:45.845751Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.602023Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:33.991476Z",
     "start_time": "2025-11-28T03:07:33.829503Z"
    }
   },
   "source": [
    "# NORMALIZING WITH MEAN 0 AND UNIT VARIANCE\n",
    "mean = X_tensor.mean(dim=0, keepdim=True)\n",
    "std = X_tensor.std(dim=0, unbiased=False, keepdim=True)\n",
    "\n",
    "# avoid division by zero for constant columns\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "X_tensor_norm = (X_tensor - mean) / std\n",
    "\n",
    "print(X_tensor_norm.shape)\n",
    "print(X_tensor_norm.mean(dim=0))  # should be ~0\n",
    "print(X_tensor_norm.std(dim=0))   # should be ~1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([115406, 500])\n",
      "tensor([-6.8555e-08, -4.5615e-08,  1.3685e-08,  2.0196e-08, -1.8378e-08,\n",
      "        -7.7480e-08, -1.3883e-08, -2.7634e-08, -8.6405e-08, -8.4620e-09,\n",
      "        -2.9088e-08, -1.9965e-08, -2.1915e-08,  3.9732e-08, -3.6889e-08,\n",
      "         1.4544e-08,  3.8542e-08,  5.5532e-09,  3.7352e-08,  4.4128e-08,\n",
      "        -1.9998e-09, -4.4822e-08,  2.4857e-08,  2.0229e-08, -1.3883e-08,\n",
      "         4.0327e-09,  2.8030e-08,  3.0542e-08,  2.0890e-08, -8.6603e-09,\n",
      "         2.8890e-08, -1.3288e-08, -3.3848e-08,  4.3500e-08, -1.8048e-08,\n",
      "        -1.4263e-08,  1.2561e-09,  1.9833e-08, -2.1089e-08, -3.1468e-08,\n",
      "         2.1287e-08, -9.4701e-09,  1.9833e-09,  1.8709e-08, -3.8277e-08,\n",
      "         1.9568e-08, -3.9732e-08,  1.9172e-09, -5.5267e-08,  1.5271e-08,\n",
      "        -7.8670e-09,  2.0031e-08, -6.3465e-09, -2.1485e-09, -8.1645e-09,\n",
      "         2.6642e-08,  4.7202e-08,  6.0027e-08, -3.1865e-08, -1.6924e-08,\n",
      "         3.4972e-08, -4.0988e-08, -4.4954e-09, -6.6407e-08,  8.7661e-08,\n",
      "        -4.4095e-08, -2.3865e-08,  1.1239e-08,  3.5963e-08,  2.1419e-08,\n",
      "         4.2310e-08, -5.2094e-08, -8.4686e-08, -2.6576e-08, -3.6096e-08,\n",
      "         6.5613e-09,  5.3020e-08, -1.5536e-08,  6.9580e-09, -1.6858e-09,\n",
      "        -6.4523e-08, -1.2164e-08, -1.8511e-08,  1.8114e-08, -7.6885e-08,\n",
      "         2.5254e-08,  2.0725e-08, -1.4808e-08, -1.3222e-09,  3.4773e-08,\n",
      "         6.5283e-09, -6.2804e-09,  1.7387e-08, -4.8921e-09,  2.8361e-08,\n",
      "        -1.4015e-08, -8.2636e-10, -3.5765e-08, -6.1151e-09, -2.5783e-08,\n",
      "        -1.5866e-09, -3.4906e-08,  1.9172e-08,  1.3486e-08, -1.9502e-08,\n",
      "        -2.0560e-08,  2.2609e-08,  2.1155e-09, -2.9815e-08,  5.4077e-08,\n",
      "        -5.8837e-09,  6.6109e-09,  5.9829e-09, -4.6871e-08,  3.3914e-08,\n",
      "        -3.0278e-08,  1.8841e-08,  2.7237e-08, -2.6973e-08, -9.7842e-09,\n",
      "        -3.0609e-08,  3.2724e-08,  2.4394e-08,  1.8742e-08, -3.3055e-08,\n",
      "         2.1353e-08,  2.9617e-08,  6.0192e-08,  3.1732e-09, -5.0177e-08,\n",
      "        -7.7678e-09,  2.8129e-08,  4.5946e-08, -2.2576e-08,  4.6276e-09,\n",
      "         2.1419e-08, -2.2411e-08, -1.8511e-09,  1.7254e-08, -2.2312e-08,\n",
      "         5.3416e-08, -1.4808e-08, -3.9203e-08,  2.3799e-08, -2.9749e-08,\n",
      "        -1.2296e-08, -7.5364e-09, -2.3733e-08, -2.7568e-08, -5.3548e-08,\n",
      "         2.2675e-08, -3.9004e-08, -2.6774e-08, -3.8079e-08,  1.0710e-08,\n",
      "         9.3214e-09,  3.0385e-08, -3.1534e-08, -3.1204e-08, -7.6026e-09,\n",
      "        -3.0278e-08, -2.5121e-09, -1.2032e-08,  4.2178e-08, -4.2359e-08,\n",
      "         3.4112e-08, -5.5466e-08, -6.6109e-11, -1.7552e-08,  3.3253e-08,\n",
      "         4.1649e-08, -1.8246e-08,  4.5748e-08,  6.3200e-08, -1.4114e-08,\n",
      "        -8.6603e-09, -1.0049e-08,  2.3006e-08, -7.0208e-08, -2.8559e-08,\n",
      "        -2.4460e-08, -1.3172e-08, -5.6193e-09,  6.7233e-08,  1.9568e-08,\n",
      "         8.1314e-09, -2.4064e-08, -3.6426e-08,  2.8824e-08, -1.3371e-08,\n",
      "        -1.1404e-08,  4.0525e-08,  4.1764e-08, -3.4840e-08,  2.8030e-08,\n",
      "        -4.6276e-09,  2.6080e-08,  6.5118e-09, -2.1155e-08,  4.1153e-08,\n",
      "         2.8559e-08,  5.2226e-08, -3.2393e-09,  1.6197e-09,  2.5518e-08,\n",
      "        -8.5281e-09,  1.2891e-08, -2.7964e-08,  3.9666e-10,  2.1535e-08,\n",
      "        -6.1878e-08,  4.8921e-09,  2.2808e-08,  4.1781e-08, -2.5419e-08,\n",
      "        -2.9088e-08, -6.5613e-09,  6.9018e-08,  3.0939e-08,  4.1120e-08,\n",
      "         1.7849e-08, -6.5779e-09, -5.7118e-08, -4.2310e-08, -5.6854e-09,\n",
      "        -2.5915e-08, -9.3875e-09, -1.3916e-08,  2.6179e-08,  1.9072e-08,\n",
      "        -3.5699e-08, -3.6294e-08,  4.7599e-09, -1.1900e-08, -2.6642e-08,\n",
      "         4.1715e-08,  1.3420e-08,  3.7814e-08, -2.4593e-08,  1.7998e-08,\n",
      "         1.3222e-10,  3.7748e-08, -1.2296e-08, -4.3235e-08, -3.4707e-09,\n",
      "         1.1106e-08, -2.8691e-08,  2.9815e-08, -7.9331e-09,  5.3813e-08,\n",
      "         4.2442e-08,  2.0097e-08,  1.3883e-08, -3.9533e-08, -2.3799e-08,\n",
      "         1.0710e-08, -3.9930e-08, -1.3552e-08,  2.9286e-08, -3.5897e-08,\n",
      "        -4.4161e-08, -5.1301e-08, -1.6131e-08,  2.9419e-08, -4.8689e-08,\n",
      "         6.5448e-08, -4.7499e-08,  2.4328e-08, -6.1482e-09, -5.4672e-08,\n",
      "        -2.6146e-08, -2.9617e-08,  4.6805e-08,  4.1186e-08, -9.3049e-09,\n",
      "         1.3486e-08,  1.2693e-08,  5.4210e-09, -1.2032e-08,  7.3513e-08,\n",
      "        -1.3354e-08, -2.0890e-08, -2.6906e-08, -1.5734e-08,  2.9088e-09,\n",
      "         2.3337e-08,  2.5849e-08,  5.0309e-08,  1.0181e-08,  1.2131e-08,\n",
      "         3.2096e-08,  1.1437e-08, -1.6180e-08,  9.2553e-10, -4.3103e-08,\n",
      "         6.3465e-09, -6.6109e-11, -1.4875e-10, -3.8343e-09, -6.0820e-09,\n",
      "        -9.2553e-10,  2.7105e-09,  2.6576e-08,  3.8013e-09,  7.9397e-08,\n",
      "        -1.4147e-08,  3.4245e-08,  3.7748e-08, -7.8670e-09,  2.3932e-08,\n",
      "         3.3583e-08, -2.2907e-08, -4.2310e-09,  2.1419e-08,  3.2790e-08,\n",
      "         5.9498e-09,  3.0741e-09, -7.5364e-09,  1.3090e-08,  2.4857e-08,\n",
      "        -1.4412e-08, -1.5866e-09, -8.2636e-09,  3.7947e-08, -4.2310e-08,\n",
      "        -3.8145e-08,  8.2636e-09,  6.5779e-09,  2.9815e-08,  3.6691e-08,\n",
      "         3.2922e-08,  5.3945e-08, -4.4128e-09, -1.5337e-08, -2.0097e-08,\n",
      "        -3.7484e-08,  3.4112e-08, -2.3865e-08, -3.3716e-08,  4.2442e-08,\n",
      "        -7.9331e-10,  7.0076e-09,  2.4659e-08, -2.1750e-08, -3.0080e-08,\n",
      "         7.3613e-08, -2.2477e-09,  3.7616e-08,  1.1767e-08, -4.0062e-08,\n",
      "         1.1503e-08, -1.9965e-08,  2.0163e-08, -2.7369e-08, -5.6193e-09,\n",
      "        -1.3817e-08, -3.4377e-09, -1.3106e-08, -7.2390e-09, -8.8586e-09,\n",
      "         1.8643e-08,  1.7056e-08, -2.5121e-09, -1.9172e-09, -2.9088e-08,\n",
      "        -1.4676e-08, -1.5866e-09, -2.5849e-08,  2.6245e-08, -1.9833e-10,\n",
      "         8.0918e-08, -1.8577e-08, -2.7948e-08, -3.5038e-09, -3.3583e-08,\n",
      "         1.5403e-08, -2.2659e-08, -6.7431e-09, -1.3585e-08,  1.3420e-08,\n",
      "         2.7634e-08,  1.6478e-08, -2.0494e-08, -1.9436e-08, -8.5942e-09,\n",
      "         3.2129e-08, -2.1221e-08, -4.9251e-08,  4.9846e-08, -1.1635e-08,\n",
      "         4.7070e-08, -1.1048e-08,  6.6770e-09,  2.8956e-08,  2.3006e-08,\n",
      "        -4.7516e-08,  3.0179e-08,  2.3799e-08,  3.8839e-08,  2.3601e-08,\n",
      "        -1.5602e-08,  2.0494e-09, -1.4544e-08,  2.6840e-08, -3.6757e-08,\n",
      "         1.9833e-09,  2.1816e-09,  1.3883e-08,  1.8577e-08, -1.3883e-09,\n",
      "         4.3566e-08,  5.9300e-08, -3.6261e-08, -2.3403e-08,  3.8575e-08,\n",
      "        -1.2296e-08,  8.7925e-09,  1.4875e-08,  7.1398e-09, -1.9833e-09,\n",
      "         3.7352e-09, -3.7682e-08,  1.3057e-09,  2.3998e-08,  5.5399e-08,\n",
      "        -3.0675e-08, -7.6356e-09, -2.4460e-09,  3.0939e-08, -1.0049e-08,\n",
      "        -3.2261e-08, -7.1398e-09,  4.5615e-09, -5.1830e-08, -6.6109e-09,\n",
      "         5.0904e-09,  2.2477e-09, -2.0626e-08,  1.8709e-08,  1.5602e-08,\n",
      "         9.7180e-09, -6.4787e-09, -1.7849e-09, -3.3385e-08, -1.5602e-08,\n",
      "        -2.7039e-08,  1.9172e-08, -3.0741e-08, -2.2477e-09,  1.9039e-08,\n",
      "        -5.5119e-08,  7.1728e-09, -2.6973e-08,  1.2296e-08,  1.0049e-08,\n",
      "         3.7054e-08, -3.4245e-08,  8.5942e-10,  2.1010e-08,  5.3879e-09,\n",
      "        -2.4196e-08,  6.1812e-08, -4.5615e-09, -1.8180e-08,  4.0789e-08,\n",
      "        -2.2180e-08,  2.9088e-09,  2.1552e-08,  6.9580e-09, -1.0577e-08,\n",
      "        -4.5714e-08,  5.0970e-08,  1.5139e-08,  2.9881e-08,  1.0049e-08,\n",
      "        -7.9331e-10,  5.4375e-08, -1.2462e-08, -4.2310e-09,  3.8740e-08,\n",
      "        -4.2971e-09, -6.4787e-09, -4.0194e-08,  5.1565e-09, -4.4954e-08,\n",
      "        -1.6065e-08, -2.0229e-08,  1.4676e-08,  2.4989e-08,  6.1614e-08,\n",
      "        -4.0657e-09,  6.0820e-09, -9.3214e-09,  3.5831e-08, -4.4558e-08,\n",
      "         8.7264e-09, -2.2708e-08,  4.3632e-09,  2.5518e-08,  1.7056e-08])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "15f8a51de1bd639b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:45.848674Z",
     "iopub.status.busy": "2025-11-16T22:57:45.847752Z",
     "iopub.status.idle": "2025-11-16T22:57:45.853456Z",
     "shell.execute_reply": "2025-11-16T22:57:45.852487Z",
     "shell.execute_reply.started": "2025-11-16T22:57:45.848635Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:34.005249Z",
     "start_time": "2025-11-28T03:07:34.001877Z"
    }
   },
   "source": [
    "print(y_tensor)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43, 16, 21,  ..., 32, 46, 33])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "ca93d745d08e1874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T22:57:48.879212Z",
     "iopub.status.busy": "2025-11-16T22:57:48.878979Z",
     "iopub.status.idle": "2025-11-16T22:57:48.898071Z",
     "shell.execute_reply": "2025-11-16T22:57:48.895867Z",
     "shell.execute_reply.started": "2025-11-16T22:57:48.879191Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:34.070317Z",
     "start_time": "2025-11-28T03:07:34.060972Z"
    }
   },
   "source": [
    "# total samples\n",
    "n_samples = len(X_tensor)\n",
    "n_train = int(0.8 * n_samples)\n",
    "n_val = n_samples - n_train\n",
    "\n",
    "# combine into a dataset\n",
    "dataset = TensorDataset(X_tensor_norm, y_tensor)\n",
    "\n",
    "# random split\n",
    "utils.set_seed(433)\n",
    "g = torch.Generator().manual_seed(433)\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=g)\n",
    "\n",
    "print(f\"Train samples: {len(train_set)}\")\n",
    "print(f\"Validation samples: {len(val_set)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 92324\n",
      "Validation samples: 23082\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "9d041bfa0fb4a52a",
   "metadata": {},
   "source": [
    "# Performing Random Search for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "id": "480f997856882f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T01:47:50.922851Z",
     "iopub.status.busy": "2025-11-17T01:47:50.922399Z",
     "iopub.status.idle": "2025-11-17T01:47:50.936834Z",
     "shell.execute_reply": "2025-11-17T01:47:50.935890Z",
     "shell.execute_reply.started": "2025-11-17T01:47:50.922824Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:07:34.123769Z",
     "start_time": "2025-11-28T03:07:34.119744Z"
    }
   },
   "source": [
    "def random_search(train_set, val_set, device, search_space, num_trials=20, grad_clip=True, gauss=True, log=True, patience=5):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter search on a hyperparameter search space.\n",
    "\n",
    "    Args:\n",
    "        train_set: training subset from training dataset\n",
    "        val_set: validation subset from training dataset\n",
    "        device: device to run training on (\"cpu\" or \"cuda\")\n",
    "        search_space: dictionary of training hyperparameters\n",
    "        num_trials: number of trials\n",
    "        grad_clip: whether to apply gradient clipping during training\n",
    "        gauss: whether to apply Gaussian noise\n",
    "        log: whether to log training and validation metrics during training\n",
    "        patience: number of epochs to wait for validation improvement before early stopping\n",
    "    \"\"\"\n",
    "    # find all hyperparameter combinations\n",
    "    keys, values = zip(*search_space.items())\n",
    "    all_combos = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    # random hyperparameter sampling\n",
    "    rng = random.SystemRandom()\n",
    "    rng.shuffle(all_combos)\n",
    "    configs = all_combos[:num_trials]\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        # --- Sample a shuffled hyperparameter combination --- #\n",
    "        params = configs[trial]\n",
    "        print(f\"\\n=== Trial {trial+1}/{num_trials} ===\")\n",
    "        print(params)\n",
    "\n",
    "        model, train_accs, val_accs, losses, best_val_acc = utils.train_and_validate(\n",
    "            train_set, val_set, device, params, grad_clip=grad_clip, gauss=gauss, log=log, patience=patience\n",
    "        )\n",
    "\n",
    "        print(f\"Trial {trial+1} finished with Best AVG Val Acc = {best_val_acc:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "95ef1e82582cdf57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T01:48:04.556245Z",
     "iopub.status.busy": "2025-11-17T01:48:04.555368Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T03:29:43.536138Z",
     "start_time": "2025-11-28T03:07:34.179297Z"
    }
   },
   "source": [
    "search_space = {\n",
    "    'hidden_size':     [4096],                          # only high values\n",
    "    'lr':              [0.005],                         # fixed\n",
    "    'weight_decay':    [0.001, 0.005, 0.01, 0.05, 0.1], # i have no idea, trying wide range\n",
    "    'batch_size':      [384, 512, 768],                 # fixed\n",
    "    'init_type':       ['xavier'],                      # fixed\n",
    "    'dropout':         [0.45, 0.5, 0.55],               # centered around sweet spot\n",
    "    'noise_std':       [0.50, 0.55, 0.60, 0.65, 0.70],  # centered around sweet spot\n",
    "    'num_epochs':      [125],                           # fixed\n",
    "    'warmup_epochs':   [8, 12, 16],                     # interacts strongly w/ noise\n",
    "}\n",
    "\n",
    "\n",
    "random_search(train_set, val_set, device, search_space, num_trials=180, grad_clip=True, gauss=True, log=False, patience=10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trial 1/180 ===\n",
      "{'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.01, 'batch_size': 768, 'init_type': 'xavier', 'dropout': 0.5, 'noise_std': 0.6, 'num_epochs': 125, 'warmup_epochs': 16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9afa52f227694d50ba7e50e03e22af93"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with Best AVG Val Acc = 82.19%\n",
      "\n",
      "=== Trial 2/180 ===\n",
      "{'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.005, 'batch_size': 768, 'init_type': 'xavier', 'dropout': 0.55, 'noise_std': 0.6, 'num_epochs': 125, 'warmup_epochs': 12}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "470dc12f260b4557b3825789d71d7f84"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 122 (no improvement for 10 epochs).\n",
      "Trial 2 finished with Best AVG Val Acc = 81.94%\n",
      "\n",
      "=== Trial 3/180 ===\n",
      "{'hidden_size': 4096, 'lr': 0.005, 'weight_decay': 0.1, 'batch_size': 512, 'init_type': 'xavier', 'dropout': 0.45, 'noise_std': 0.6, 'num_epochs': 125, 'warmup_epochs': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eff6143c548c4cc898ed9a9a83a536fc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      1\u001B[39m search_space = {\n\u001B[32m      2\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mhidden_size\u001B[39m\u001B[33m'\u001B[39m:     [\u001B[32m4096\u001B[39m],                          \u001B[38;5;66;03m# only high values\u001B[39;00m\n\u001B[32m      3\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m'\u001B[39m:              [\u001B[32m0.005\u001B[39m],                         \u001B[38;5;66;03m# fixed\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     10\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mwarmup_epochs\u001B[39m\u001B[33m'\u001B[39m:   [\u001B[32m8\u001B[39m, \u001B[32m12\u001B[39m, \u001B[32m16\u001B[39m],                     \u001B[38;5;66;03m# interacts strongly w/ noise\u001B[39;00m\n\u001B[32m     11\u001B[39m }\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m180\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_clip\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgauss\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mrandom_search\u001B[39m\u001B[34m(train_set, val_set, device, search_space, num_trials, grad_clip, gauss, log, patience)\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m=== Trial \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrial+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_trials\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m ===\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(params)\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m model, train_accs, val_accs, losses, best_val_acc = \u001B[43mutils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_clip\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgrad_clip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgauss\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgauss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpatience\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTrial \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrial+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m finished with Best AVG Val Acc = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_val_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m%\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Team-26/modules/utils.py:178\u001B[39m, in \u001B[36mUtils.train_and_validate\u001B[39m\u001B[34m(self, train_tensor, val_tensor, device, params, grad_clip, gauss, log, patience)\u001B[39m\n\u001B[32m    175\u001B[39m model.train()\n\u001B[32m    176\u001B[39m running_loss, correct, total = \u001B[32m0\u001B[39m, \u001B[32m0\u001B[39m, \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# --- GAUSSIAN NOISE --- #\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    730\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    736\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    738\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    786\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    787\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m788\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    790\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:50\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.auto_collation:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33m__getitems__\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     52\u001B[39m         data = [\u001B[38;5;28mself\u001B[39m.dataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/dataset.py:416\u001B[39m, in \u001B[36mSubset.__getitems__\u001B[39m\u001B[34m(self, indices)\u001B[39m\n\u001B[32m    414\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__([\u001B[38;5;28mself\u001B[39m.indices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m416\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/dataset.py:207\u001B[39m, in \u001B[36mTensorDataset.__getitem__\u001B[39m\u001B[34m(self, index)\u001B[39m\n\u001B[32m    206\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/pycharm_py313/lib/python3.13/site-packages/torch/utils/data/dataset.py:207\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    206\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(tensor[index] \u001B[38;5;28;01mfor\u001B[39;00m tensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.tensors)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4466f976ce00416"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
